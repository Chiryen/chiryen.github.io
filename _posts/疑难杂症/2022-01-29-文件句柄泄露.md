# 文件句柄泄露

## 背景

线上base服务报警，pod memory利用率达到90%以上，然后自动重启。但jvm内存平稳正常无飙升现象。

## 排查思路

1. 报警时查看base服务日志，未发现异常

2. 根据监控平台查看pod oom之前一个小时的请求，发现每次都存在一些文件导入导出的请求，怀疑和文件的操作有关。

3. 猜想是不是文件数据量太大，读写内存导致的。但jvm堆内存没有明显上升，排除这个可能。

4. 既然堆内存没有什么变化，pod内存上升，也就是说问题发生在堆之外的资源消耗上。堆之外的资源，和文件相关的，想到的就是文件句柄或者连接未释放。

5. 通过命令查看未释放的句柄

   1. ``ps aux | grep java `` 找出进程号
   2. ``lsof -p <pid> | grep deleted`` 查看未释放的文件句柄

   ![image-20220129161755651](https://tva1.sinaimg.cn/large/008i3skNly1gyum6559e7j31tq0p8trp.jpg)

6. 发现有大量文件处于deleted 状态，表示文件已删除但空间没有释放。而默认情况下一个进程最多打开1024个文件句柄

7. 大量连接没有释放，相当于进程和文件之间存在着大量的“管道”，而进程需要去维护这些“管道”，它占用了pod的内存，超过了cgroup的限制，导致pod oom

## 解决方案

1. 使用sonar扫描代码，检查出所有未释放资源的“坏”代码
2. 使用try with resources 修复，自动释放资源

## 思考

1. 文件或连接打开后要记得关闭
2. 要秉承”自己创建的流，自己负责关闭“，从目前遇到的设计思路以及开源方法来看，都不会随意关闭用户传递给函数的流（可能影响用户后续使用）
3. 开源或封装的函数，尽量了解其运行规则，查看流的操作是否合规，避免其带来风险

